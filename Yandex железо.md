---
tags:
  - Writing
type: page
---
---
### [**Закаливание детектора автомобиля радарными точками**](https://youtu.be/c1IBvEHwBmo?si=N9gz1YTK_7ticKfg)

Доклад без глубоких технических деталей, но всё равно любопытный. Несколько моментов, на которые стоит обратить внимание:

- работают в рамках **BEV-Fusion** с собственными доработками;
- подчёркивают важность возможности безопасно включать и отключать разные каналы (лидар, радар, камера) — критично для отказоустойчивости;
- радарный детектор слабее лидарного: данные шумные и сильно разреженные;
- метрики только по радару не приводились — оценивали в связке с камерами;
- радар выступает скорее как резервный источник, если лидары по какой-то причине стали недоступны;
- наибольший прирост метрик дали агрегация радарных точек из прошлых кадров и добавление индекса конкретного радара как дополнительного признака;
- предложили собственную метрику, более «толерантную» к ошибкам локализации на дальних и перекрытых объектах (например, ошибка 10 м на 100 м дистанции не критична для запасного контура CV).

Год назад я делал для коллег обзор методов сенсорного слияния и мы тоже выделяли **BEV-Fusion**. Идея хоть и не новая, но до сих пор актуальна — именно потому, что построение BEV-карты в этом подходе не завязано жёстко на лидар. Каждый сенсор независимо проецируется на вид сверху с помощью матрицы проекции. Поэтому можно, условно, отключить лидары и всё равно получить BEV-представление сцены по радарам и камерам.

Есть и минусы:
- гипотеза «земля плоская»: камерные признаки сверху могут не совпадать с лидарными в местах сложного рельефа - например человек, стоящий на возвышенности, спроецируется дальше своего реального положения;
- углы установки сенсоров должны быть стабильны относительно земли, иначе проекции будут «плыть» — особенно это заметно будет для объектов на больших дистанциях при раскачивании беспилотника.

---

### [**От идеи до реальности: как мы создаём лидары**](https://youtu.be/p3eiLQ5diAY?si=hbb_0UZt-gQ38JYF)

  

Обзорный доклад про особенности лидаров, полезен для общего понимания. Я, например, наконец-то запомнил:

- **круговой лидар** чаще всего = твердотельные излучатели на 950 нм (по числу излучателей = число лучей);
    
- **дальнобойные секторальные лидары** обычно строятся на одном мощном излучателе 1550 нм, который сканируют зеркала по вертикали и горизонтали.
    

  

Интересно, что 1550-нм лидары могут быть в разы мощнее 950-нм именно из-за безопасности для зрения.

  

Ещё один любопытный момент — работа днём и ночью:

- длину волны больше 1550 нм не используют, чтобы приёмник не путал сигнал с естественным тепловым излучением (особенно заметно ночью);
    
- днём возникает конкуренция с отражённым солнечным светом (и чем ближе длина волны к видимому диапазону, тем сильнее).
    

  

В теории ночью картинка должна быть чище и метрики — выше. Но на практике у 3D-детекторов ночью часто падает качество! Авторы BEV-Fusion этот парадокс не комментируют. Вероятное объяснение — в датасете **NuScenes**: ночных кадров мало, разметка сложнее и шумнее, что снижает обобщаемость моделей.

---

### [**Переходы. Светофоры. Роботы**](https://youtu.be/j5o2JhIqt0o?si=IKQwDATdkhThe4GW)

  

Доклад о том, как тяжело работать с редкими примерами и «длинным хвостом» распределения.

- Часть проблем решается «докруткой» системы и дообучением: добавили кадры с перекрытым светофором, ввели временной контекст в трансформер.
    
- Другая часть (например, предсказание намерений автомобилистов на переходе) требует уже не эвристик, а сквозного ML-подхода, где распознавание и планирование объединены в одной модели. На мой взгляд, это самая интересная часть — универсальная идея, которая пока в стадии разработки.
    

---

### [**Обзор системы очистки сенсора автономного ТС**](https://youtu.be/Q5DXhrkEodA?si=H5fzhIowvrt0lVhX)

  

Про очистку сенсоров беспилотных грузовиков (спойлер: воздушно-капельные форсунки). Несколько моментов:

- лидара чистят «по половинкам», чтобы не терять все точки сразу;
    
- можно чистить не по расписанию, а по факту загрязнения — это экономит омывайку;
    
- для камер собирают датасет с «грязными/чистыми» примерами, для лидаров — тоже, но всегда сверяют с камерой, иначе сложно понять источник пропажи точек.
    

---

### [**Как Embedded снижает стоимость нейронных сетей?**](https://youtu.be/1PWVZ9NeWUY?si=9O8lQKHPxXMfhbso)

  

Вторая часть доклада — про оптимизацию кода под железо. Забавный пример: код удвоился в размере, но стал куда более эффективным под конкретную платформу. Такой код, как утверждают авторы, может ускорить даже CUDA-инференс на порядки! Обычно те, кто обучает модели, так глубоко в инференс не копают, но в идеале к этому стоит стремиться.

---

### [**Дизайн автономного грузовика**](https://youtu.be/yPfM7YcAN6k?si=vxRwyAAZ2UykYML7)

  

Про дизайн обтекателей сенсорного набора автономного грузовика. Эти кожухи должны быть и функциональными, и эстетичными.

Любопытный момент: перед выбором места для логотипа сделали «карту загрязнения» кузова. В зонах, которые сильнее всего пачкаются при езде, логотип ставить явно не стоит.

---

Хочешь, я сделаю ещё компактную выжимку — прям «tl;dr» для каждого доклада в 1–2 строки?