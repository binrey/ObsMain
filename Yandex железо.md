---
tags:
  - Writing
type: page
---
---

[Закаливание детектора автомобиля радарными точками](https://youtu.be/c1IBvEHwBmo?si=N9gz1YTK_7ticKfg)
Без глубоких подробностей, но все равно интересный доклад про обучение 3d-детектора на радарных данных. На что можно обратить внимание:
- работают в рамках bev-fusion архитектуры со своими улучшениями
- выделяют этот подход благодаря возможности безопасно подключать и отключать разные каналы данных (лидар, радар, камера), что важно с точки зрения отказоустойчивости
- радарный детектор «слабее» лидарного: он шумный и очень разреженный
- только радарных метрик даже не приводилось, смотрели в связке с камерами
- радар используется скорее как запасной источник данных если лидары по какой-нибудь причине стали недоступны
- больше всего метрику подняли с помощью аггрегации радарных точек с прошлых кадров и добавлением индекса конкретного радара как дополнителного признака
- сделали некую свою метрику, более толерантную к ошибке локализации для дальних объектов и сильно перекрытых (условно, на 100 метрах ошибка в 10 метров не сильно критична при оценке качества работы запасного контура компьютерного зрения)

Год назад я делал для коллег обзор методов объединения сенсоров и мы так же выделяли Bev-fusion. Это хоть и не новая но, видимо, до сих пор актуальная идея как раз за счет того, что в ней построение BEV-карты не завязано на лидарные точки - каждый сенсор (его карта признаков) проецируется на вид сверху независимо от остальных, используя матрицы проекции. По этому можно условно безопасно отключить лидары и все равно получать BEV-представление окружающей сцены по радарам и камерам. Но в теории в таком подходе есть и свои слабые места по сравнению с ранним связываением на основе лидарных точек. Во первых, гипотеза, что земля плоская: "картиночные" признаки не совпадут на виде сверху с лидарными признаками в местах локального изменения рельефа. Во вторых, углы установки сенсоров не должны меняться относительно земли или это изменение нужно отслеживать инерциальными датчиками. Иначе небольшое раскачивание ТС может приводить к значительным расхождениям проекций признаков на больших расстояниях.

[От идеи до реальности: как мы создаём лидары](https://youtu.be/p3eiLQ5diAY?si=hbb_0UZt-gQ38JYF)
Обзорный доклад про особенности лидаров, будет полезно для общего развития. Я, например, наконец-то запомнил, что круговой лидар это скорее всего лидар с твердотельными излучателями на 950 нм (сколько лучей - столько излучателей), а дальнобойные секторальные лидары чаще будут укомплектованы одним мощным излучателем с длиной волны 1550 нм, которого зеркала разбрасывают по вертикали и горизонтали. Последние могут быть в разы мощнее 950 нанометровых, оказывается, в основном по причине безопасности для зрения.
Еще одна интересная часть доклада была про особенности работы ночью и днем. Длину волны длиннее 1550 не делают потому что иначе приемник лидара будет путать свой луч с естественным тепловым излучением объектов вокруг. Это будет хорошо заметно ночью. А днем начинается конкуренция с отраженным солнечным светом (и чем меньше длина волны лидара, т.е. чем ближе к видимому диапозону длинн волн - тем эта конкуренция сильнее). По этому в теории ночью, в условиях меньшего лишнего излучения, лидар должен давать менее шумную и более чистую картинку, что в свою очередь должно поднимать валидационные метрики различных 3д-детекторов. Но на практике можно увидеть обратное - падение метрик 3д-детектора в ночное время! Авторы статьи bev-fusion никак не коментируют свои контр-интуитивные результатыю. Я тоже не нашел однозначного ответа. Скорее всего дело в самом датасете Nuscenes: ночных кадров меньше и их сложнее размечать, там больше шума в разметке, все это не способствует повышению обобщаемости модели.
[Переходы. Светофоры. Роботы](https://youtu.be/j5o2JhIqt0o?si=IKQwDATdkhThe4GW)
Тоже неплохой доклад по верхам о том как сложно работать с редко встречающимися примерам.
[Обзор системы очистки сенсора автономного ТС](https://youtu.be/Q5DXhrkEodA?si=H5fzhIowvrt0lVhX)

[Дизайн Автономного грузовика](https://youtu.be/yPfM7YcAN6k?si=vxRwyAAZ2UykYML7)

[Как Embedded снижает стоимость нейронных сетей?](https://youtu.be/1PWVZ9NeWUY?si=9O8lQKHPxXMfhbso)