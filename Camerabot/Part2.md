Робот отправляет на хост изображения с камеры в уменьшенном до 640x480 пикс. размере. И хотя изображение передаётся в уменьшенном размере, это даёт лишь ограниченный выигрыш по задержке. В авторегрессионных VLM основное время инференса тратится на генерацию ответа: каждый следующий токен вычисляется отдельным шагом декодера. В результате именно длина ответа, а не размер кадра или промпта, становится главным фактором задержки. При выборе длины ответа важен баланс: с одной стороны хочется генерировать ответ как можно короче, в пределе только управляющую команду; с другой стороны перед окончательным решением модели нужно дать «подумать вслух».