# Робот на VLM в домашних условиях

![Для привлечения внимания](real_drive_1.gif)
## Введение

В системах автономного вождения принято выделять два основных подхода — **модульный** и **сквозной (End-to-End)**. Кратко напомню их суть.

Модульный подход разделяет задачу на отдельные компоненты: детекция объектов, предсказание их движения, планирование траектории и управление. Каждый модуль оптимизируется по своей локальной метрике, что упрощает разработку и отладку, но может приводить к накоплению ошибок и потере информации между этапами обработки.

Сквозной подход объединяет все этапы в единую модель глубокого обучения, которая напрямую преобразует сырые данные сенсоров в управляющие команды. Такой подход позволяет избежать ручного проектирования признаков, обеспечивает совместную оптимизацию всех компонентов по глобальному критерию качества вождения и потенциально лучше обобщается на новые ситуации. Однако взамен мы получаем черный ящик, который сложно контролировать и тонко настраивать.

На практике сегодня модульные архитектуры лежат в основе большинства рабочих и коммерческих систем автономного вождения, тогда как end-to-end-подход чаще встречается в исследовательских прототипах и демонстрациях. Однако [bitter lesson](http://www.incompleteideas.net/IncIdeas/BitterLesson.html) напоминает, что методы, способные эффективно масштабироваться с ростом данных и вычислений (машинное обучение), со временем берут верх. А данных в индустрии со временем становится только больше. Поэтому за развитием сквозного подхода стоит как минимум следить.

Сквозное обучение можно реализовать по-разному. Можно реализовать имитационное обучение (Imitational learning) на данных «наблюдение-действие». Затем добавить  симулятор - среду с которой можно взаимодействовать, чтобы покрыть сложные сценарии обучением с подкреплением (Reinforcement learning). Можно улучшить симулятор, обучив модель мира, чтобы попытаться решить проблему переноса знаний (Sim to real knowledge transfer). Все эти методы предполагают наличие данных в том или ином количестве и обучение на них.

Использование больших языковых и визуально-языковых моделей при этом не является обязательным компонентом end-to-end-автопилота. Сегодня их чаще рассматривают как вспомогательный слой — источник обобщенных знаний, инструмент интерпретации или интерфейс для объяснения поведения системы человеку.

Например, компания Wayve демонстрирует применение визуально-языковых моделей для пояснения решений своего автопилота: система способна не только ехать по маршруту, но и формулировать объяснения своих действий на естественном языке, что частично приоткрывает «черный ящик» принятия решений.

![wave](wave.gif)

 В предельном случае можно пойти еще дальше и попытаться использовать универсальную визуально-языковую модель в режиме zero-shot — без специализированных данных и обучения под задачу вождения. Такая система потенциально способна не только понимать сцену (как например модели типа grounding DINO), но и принимать решения о дальнейших действиях в контексте поставленной задачи.

Автопилот на VLM внешне будет очень похож на приведенную выше демонстрацию от Wayve. Однако если Wayve использовал VLM как дополнительный инструмент к своему тщательно обученному агенту-водителю, в нашем беспилотнике VLM будет “отдуваться за всех”. Безусловно, это лишь демонстрация без шансов на реальное применение: во-первых, универсальные VLM скорее всего не будут иметь достаточных для серьезного применения навыков, а во-вторых их авторегрессионный инференс слишком медленный для автономного вождения.
## Архитектура

Выбор архитектуры в первую очередь определяется ограничениями, которые накладывает модель. Для управления роботом недостаточно «видеть» сцену. Модель должна одновременно понимать изображение, интерпретировать инструкцию или цель и выдавать устойчивое, формализуемое решение. Большинство быстрых vision-моделей на это не рассчитаны: они способны описывать визуальную сцену, но не действовать в роли агента.

VLM, обученные в instruct-парадигме, эту проблему решают. Они способны рассуждать и следовать системным правилам (важно, например, всегда заканчивать свой ответ командой управления из предзаданного списка). Однако за эту универсальность приходится платить вычислительной сложностью. Минимально рабочим вариантом по моим тестам будет локальная VLM начиная с 7B параметров. Для мобильного робота с ARM-процессором и жёсткими энергетическими рамками такой класс моделей оказывается практически недоступным.

Из этого ограничения логически вытекает архитектурное разделение: интеллектуальная часть выносится за пределы робота, а сам робот превращается в минималистичный исполнитель. На его стороне остаются только сенсоры и низкоуровневое управление движением. Камера выдаёт кадры, контроллер исполняет команды скорости и поворота. Вся вычислительная нагрузка концентрируется на хост-стороне. Именно там располагается VLM, принимающая изображение, инструкцию и историю прошлых состояний (при наличии), интерпретирующая ситуацию и формирующая управляющее воздействие. Хост не управляет роботом напрямую — он лишь транслирует результат рассуждения в простой и надёжный набор команд, понятный исполнительному уровню.

Это не полноценный автономный робот, но зато доступный способ быстро проверить интересные гипотезы. Цена этого подхода — задержка сети и зависимость от соединения. Для моих экспериментов было достаточно домашнего Wi-Fi, но при необходимости можно перейти на соединение по интернет-кабелю (патч-корду).

Важно подчеркнуть, что при физической распределённости система остаётся логически end-to-end. Поток данных начинается с изображения камеры и заканчивается командой движения, минуя классические промежуточные модули детекции, трекинга и планирования. VLM в этой архитектуре объединяет в себе восприятие, рассуждение, планирование и политику действий, пусть и размещённые вне корпуса робота.

Вот такой сетап использовался в эксперименте:
- ноутбук с картой RTX4080 12Гб в качестве хоста
- миникомпьютер RaspberryPi5 с широкоугольной pi-камерой на колесном ровере

На хосте и роботе развернут ROS2. Робот отправляет на хост изображения с камеры в уменьшенном до 640x480 пикс. размере. И хотя изображение передаётся в уменьшенном размере, это даёт лишь ограниченный выигрыш по задержке. В авторегрессионных VLM основное время инференса тратится на генерацию ответа: каждый следующий токен вычисляется отдельным шагом декодера. В результате именно длина ответа, а не размер кадра или промпта, становится главным фактором задержки. При выборе длины ответа важен баланс: с одной стороны хочется генерировать ответ как можно короче, в пределе только управляющую команду; с другой стороны перед окончательным решением модели нужно дать «подумать вслух».

На хосте помимо ROS2 запущена ollama с qwen2.5vl:latest — квантизованная версия на 7 миллиардов параметров. В доступе также есть версия на 3B параметров, она может работать с хорошей скоростью, почти в реальном времени, но эксперименты показали, что эта версия плохо понимает изображения. Версия latest неплохо понимает сцену и следует указаниям промпта, но работает с частотой всего около 1 fps. Это очень медленно — робот постоянно останавливается в ожидании обработки очередного кадра, но этого достаточно для тестов и демонстрации.

## Работа с моделью

Задача для модели простая — увидеть в кадре объект и направить робота к нему. Скорость оставлена фиксированной. Повороты, для упрощения, дискретные — одна команда на поворот означает смену курса на фиксированный угол.

Ключевая идея в формировании управляющего промпта — сделать его максимально простым и универсальным, дать модели максимальную свободу формирования логики управляющего сигнала, заложить как можно меньше так называемых inductive bias. Таким образом можно проверить, какие знания есть в модели и как их лучше использовать. После множества тестов близкий к оптимальному управляющий промпт выглядит так:
```
Available commands to robot:
<FORWARD> 
<RIGHT>
<LEFT> 
<BACK>

Your goal:
Using available commands to correct your direction get close to WHITE BALL as much as possible.

1. Do you see WHITE BALL on the floor?
2. Where the WHITE BALL located: near the center of a frame, close to the left side or right side of image?
3. Turn left if WHITE BALL is near the left side of image
4. Turn right if WHITE BALL is near the right side of image
5. Think before give answer. What one available command to choose to achieve the goal?
```

Полностью избежать конструкций вида «если видишь А, то делай Б» не получилось — пункты 3 и 4 жестко навязывают логику движения, а хотелось бы, чтобы нейросеть сама это придумала без подсказок. Но без этих инструкций модель слишком плохо понимала, куда нужно двигаться. Например, встречались ответы вида: «я вижу мяч, он находится справа, нужная команда — повернуть налево». Модель не объясняет детальнее логику принятия решения, что, вероятно, связано с отсутствием подобных навыков у нейросети — в обучающем датасете было очень мало подобных примеров.

Если парсер ответа нейросети находит одну из возможных команд, отправляется соответствующий управляющий сигнал роботу.

## Проверка в симуляции

Прежде чем покупать робота с камерой и миникомпьютером, полезно всё проверить в симуляторе. Webots прост и достаточно функционален. Он позволит протестировать быстродействие конкретного железа и отладить управляющий промпт. В этом случае всё происходит на хосте: модель, завернутая в ROS2-ноду, управляет виртуальным роботом в виртуальной комнате.

Ниже представлен пример такой симуляции, на которой виртуальный робот в целом успешно преследует белый мячик. Видео ускорено в 5 раз:

![webots simulation](webots.gif)

## Работа в реальном мире

Можно было остановиться на этапе симуляции, так как работа с VLM будет идентичной. Однако было интересно вывести робота в реальность. Основные изменения носят технический характер:
1. Переход на упомянутую выше схему хост-робот. Для этого на роботе нужно установить ROS2 в контейнере для ARM-процессора Raspberry Pi, настроить видимость камеры из контейнера (что оказалось непростой задачей).
2. Корректировка констант движения, так как робот отличается от симуляции и по массе, и по габаритам (вместо точного воспроизведения модели в Webots проще подстроить параметры под реальный робот). ==В серьезных беспилотных системах есть модуль контроля с обратной связью, приводящей действительную скорость к заданной в каждый момент времени. Наш робот не имеет такого модуля, поэтому он будет по-разному себя вести на разных типах покрытия.==

Важно отметить, что логика работы с VLM при переходе из симуляции в реальный мир не меняется. Благодаря значительной обобщающей способности модели белый шар в симуляции и белый мячик в реальности воспринимаются как один и тот же объект и текстовый ответ модели не меняется.

Результат выполнения задачи представлен на видео в начале статьи. Ниже — еще один пример. Тут хорошо видно, как робот целенаправленно преследует свою цель, отъезжает назад, чтобы снова увидеть потерянный из вида объект в соответствии с пунктом 5 инструкции:

![real world test 2](real_drive_2.gif)

В целом он может довольно долго ездить в таком режиме) Как было обещано, демонстрация весьма похожа на презентацию Wayve, единственное, хочется уменьшить частоту логов модели, их сложно читать в реальном времени. Например можно опускать ответы модели, не меняющие предыдущую финальную команду.

## Выводы




